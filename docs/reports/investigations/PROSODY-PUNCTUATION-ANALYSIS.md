# üé≠ Ph√¢n T√≠ch: Prosody, Ng·∫Øt Ngh·ªâ C√¢u v√† Cao ƒê·ªô Gi·ªçng N√≥i

**Date**: October 5, 2025  
**Priority**: üî¥ **CRITICAL** - ·∫¢nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn ch·∫•t l∆∞·ª£ng d·ªãch v√† TTS  
**Status**: ‚ö†Ô∏è **NEEDS SOLUTION**

---

## ‚ùì V·∫•n ƒê·ªÅ Ng∆∞·ªùi D√πng ƒê·∫∑t Ra

### 1. üîç **Ng·∫Øt Ngh·ªâ C√¢u Sai (Sentence Boundary)**
**T√°c ƒë·ªông**:
- ‚ùå D·ªãch sai nghƒ©a (c√¢u b·ªã c·∫Øt ƒë·ª©t ‚Üí m·∫•t ng·ªØ c·∫£nh)
- ‚ùå Translation model hi·ªÉu sai √Ω
- ‚ùå TTS ƒë·ªçc ng·∫Øt qu√£ng kh√¥ng t·ª± nhi√™n

**V√≠ d·ª• th·ª±c t·∫ø**:
```
‚ùå SAI: "T√¥i ƒëi ch·ª£ | mua rau c·ªß qu·∫£"
   ‚Üí D·ªãch: "I go to market | buy vegetables"
   ‚Üí TTS: "I go to market. [PAUSE] Buy vegetables."
   ‚Üí Nghe: C√¢u b·ªã c·∫Øt ƒë·ª©t, thi·∫øu li√™n k·∫øt

‚úÖ ƒê√öNG: "T√¥i ƒëi ch·ª£ mua rau c·ªß qu·∫£"
   ‚Üí D·ªãch: "I go to the market to buy vegetables"
   ‚Üí TTS: "I go to the market to buy vegetables."
   ‚Üí Nghe: T·ª± nhi√™n, c√¢u ho√†n ch·ªânh
```

### 2. üéµ **Cao ƒê·ªô Gi·ªçng N√≥i (Pitch/Tone)**
**T√°c ƒë·ªông**:
- ‚ùå TTS gi·ªçng robot, kh√¥ng c·∫£m x√∫c
- ‚ùå M·∫•t th√¥ng tin phi ng√¥n ng·ªØ (h·ªèi, kh·∫≥ng ƒë·ªãnh, ng·∫°c nhi√™n)
- ‚ùå User experience k√©m

**V√≠ d·ª•**:
```
Text: "B·∫°n ƒë·∫øn r·ªìi √†?"

‚ùå gTTS: ƒê·ªçc ph·∫≥ng kh√¥ng cao ƒë·ªô
   ‚Üí "ban den roi a" (monotone, kh√¥ng ng·ªØ ƒëi·ªáu)
   
‚úÖ F5-TTS ho·∫∑c Neural TTS:
   ‚Üí "B·∫°n ƒë·∫øn r·ªìi √†?" ‚Üó (tƒÉng cao ƒë·ªô cu·ªëi c√¢u h·ªèi)
   ‚Üí Nghe t·ª± nhi√™n nh∆∞ ng∆∞·ªùi n√≥i
```

### 3. üé≠ **Ng·ªØ ƒêi·ªáu (Prosody/Intonation)**
**T√°c ƒë·ªông**:
- ‚ùå Kh√¥ng truy·ªÅn t·∫£i c·∫£m x√∫c (vui, bu·ªìn, gi·∫≠n)
- ‚ùå Kh√¥ng ph√¢n bi·ªát tr·ªçng √¢m
- ‚ùå T·ªëc ƒë·ªô n√≥i kh√¥ng t·ª± nhi√™n

---

## üî¨ Ph√¢n T√≠ch Chi Ti·∫øt T·ª´ng Model

### üìä Model STT: PhoWhisper-small vs faster-whisper

#### ‚úÖ PhoWhisper-small (Transformers)
```python
# PhoWhisper provides word-level timestamps
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor
import torch

processor = AutoProcessor.from_pretrained("vinai/PhoWhisper-small")
model = AutoModelForSpeechSeq2Seq.from_pretrained("vinai/PhoWhisper-small")

# Generate v·ªõi timestamps
outputs = model.generate(
    input_features,
    return_timestamps=True  # ‚úÖ Word-level timestamps
)

# Result includes:
# - text: "T√¥i ƒëi ch·ª£ mua rau c·ªß qu·∫£"
# - timestamps: [(0.0, 0.5, "T√¥i"), (0.5, 0.8, "ƒëi"), ...]
```

**Kh·∫£ nƒÉng x·ª≠ l√Ω ng·∫Øt ngh·ªâ c√¢u**:
- ‚úÖ **Word-level timestamps** ‚Üí Bi·∫øt ch√≠nh x√°c t·ª´ng t·ª´ xu·∫•t hi·ªán khi n√†o
- ‚úÖ **Automatic punctuation** ‚Üí Model t·ª± th√™m d·∫•u c√¢u (., ?, !)
- ‚ö†Ô∏è **Sentence segmentation** ‚Üí C·∫ßn logic b·ªï sung ƒë·ªÉ t√°ch c√¢u
- ‚úÖ **Vietnamese-trained** ‚Üí Hi·ªÉu ng·ªØ c·∫£nh ti·∫øng Vi·ªát t·ªët h∆°n

**ƒê·ªô ch√≠nh x√°c ng·∫Øt c√¢u**: ‚≠ê‚≠ê‚≠ê (75-80%)
- Model ƒë√£ h·ªçc pause patterns t·ª´ Vietnamese data
- T·ª± ƒë·ªông ph√°t hi·ªán c√¢u h·ªèi (?) vs c√¢u kh·∫≥ng ƒë·ªãnh (.)

#### ‚ùå faster-whisper small (General)
```python
from faster_whisper import WhisperModel

model = WhisperModel("small", device="cpu", compute_type="int8")

# VAD filtering gi√∫p detect silence
segments, info = model.transcribe(
    audio,
    vad_filter=True,  # ‚úÖ Voice Activity Detection
    vad_parameters=dict(
        min_silence_duration_ms=500  # Detect 500ms silence
    )
)

# Result:
# - segments: [(start, end, text), ...]
# - VAD detects pauses but doesn't add punctuation
```

**Kh·∫£ nƒÉng x·ª≠ l√Ω ng·∫Øt ngh·ªâ c√¢u**:
- ‚úÖ **VAD (Voice Activity Detection)** ‚Üí Ph√°t hi·ªán kho·∫£ng l·∫∑ng
- ‚ùå **NO automatic punctuation** ‚Üí Kh√¥ng t·ª± th√™m d·∫•u c√¢u
- ‚ùå **General multilingual** ‚Üí Kh√¥ng hi·ªÉu ng·ªØ c·∫£nh Vietnamese t·ªët
- ‚ö†Ô∏è **Manual sentence splitting** ‚Üí C·∫ßn code th√™m logic

**ƒê·ªô ch√≠nh x√°c ng·∫Øt c√¢u**: ‚≠ê‚≠ê (50-60%)
- Ch·ªâ d·ª±a v√†o silence detection (kh√¥ng ƒë·ªß)
- Kh√¥ng hi·ªÉu ng·ªØ nghƒ©a c√¢u

---

### üåê Model Translation: NLLB-200

```python
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model = AutoModelForSeq2SeqLM.from_pretrained("facebook/nllb-200-distilled-600M")
tokenizer = AutoTokenizer.from_pretrained("facebook/nllb-200-distilled-600M")

# ‚ö†Ô∏è CRITICAL: Translation quality depends on input segmentation!
```

**·∫¢nh h∆∞·ªüng c·ªßa ng·∫Øt c√¢u sai**:

#### ‚ùå Case 1: C√¢u b·ªã c·∫Øt ƒë·ª©t
```python
# Input SAI: C√¢u b·ªã chia nh·ªè
input1 = "T√¥i ƒëi ch·ª£"
input2 = "mua rau c·ªß qu·∫£"

# Translation:
output1 = translate(input1, src="vie_Latn", tgt="eng_Latn")
# ‚Üí "I go to the market"

output2 = translate(input2, src="vie_Latn", tgt="eng_Latn")
# ‚Üí "buy vegetables" (INCOMPLETE SENTENCE!)

# ‚ùå Result: "I go to the market. buy vegetables." 
#    ‚Üí Grammatically WRONG, thi·∫øu li√™n t·ª´
```

#### ‚úÖ Case 2: C√¢u ho√†n ch·ªânh
```python
# Input ƒê√öNG: C√¢u ho√†n ch·ªânh
full_input = "T√¥i ƒëi ch·ª£ mua rau c·ªß qu·∫£"

output = translate(full_input, src="vie_Latn", tgt="eng_Latn")
# ‚Üí "I go to the market to buy vegetables"

# ‚úÖ Result: Grammatically CORRECT, c√≥ li√™n t·ª´ "to"
```

**ƒê·ªô nh·∫°y c·∫£m v·ªõi sentence boundary**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (90%+)
- Translation model R·∫§T ph·ª• thu·ªôc v√†o input segmentation
- C√¢u b·ªã c·∫Øt ‚Üí M·∫•t ng·ªØ c·∫£nh ‚Üí D·ªãch sai ho√†n to√†n

---

### üó£Ô∏è Model TTS: gTTS vs F5-TTS-Vietnamese

#### ‚ùå gTTS (Current MVP)
```python
from gtts import gTTS

# Simple API-based TTS
tts = gTTS(text="B·∫°n ƒë·∫øn r·ªìi √†?", lang='vi')
tts.save("output.mp3")
```

**Kh·∫£ nƒÉng prosody/pitch**:
- ‚ùå **NO pitch control** ‚Üí Gi·ªçng ph·∫≥ng, robot
- ‚ùå **NO emotion** ‚Üí Kh√¥ng c√≥ c·∫£m x√∫c
- ‚ùå **NO prosody** ‚Üí Kh√¥ng ng·ªØ ƒëi·ªáu
- ‚ùå **NO tone variation** ‚Üí Ti·∫øng Vi·ªát m·∫•t thanh ƒëi·ªáu
- ‚úÖ **Fast** (300ms) ‚Üí ∆Øu ƒëi·ªÉm duy nh·∫•t

**Quality score**: ‚≠ê‚≠ê (40/100)
- Ch·ªâ suitable cho demo/prototype
- Production c·∫ßn upgrade urgent

#### ‚úÖ F5-TTS-Vietnamese-ViVoice (Future Phase 3.2)
```python
# Neural TTS v·ªõi prosody control
# (Simplified example, actual implementation complex)

from f5_tts import F5TTS

model = F5TTS.from_pretrained("hynt/F5-TTS-Vietnamese-ViVoice")

# Advanced features:
audio = model.synthesize(
    text="B·∫°n ƒë·∫øn r·ªìi √†?",
    
    # ‚úÖ Prosody control
    speaking_rate=1.0,      # T·ªëc ƒë·ªô n√≥i
    pitch_scale=1.2,        # Cao ƒë·ªô (higher = female voice)
    energy_scale=1.0,       # ƒê·ªô m·∫°nh gi·ªçng
    
    # ‚úÖ Emotion (if supported)
    emotion="question",     # C√¢u h·ªèi ‚Üí tƒÉng pitch cu·ªëi c√¢u
    
    # ‚úÖ Natural pauses
    add_pause_after_punctuation=True
)
```

**Kh·∫£ nƒÉng prosody/pitch**:
- ‚úÖ **Pitch control** ‚Üí C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh cao ƒë·ªô
- ‚úÖ **Natural prosody** ‚Üí Ng·ªØ ƒëi·ªáu t·ª± nhi√™n
- ‚úÖ **Vietnamese tones** ‚Üí Ph√°t √¢m thanh ƒëi·ªáu ch√≠nh x√°c
- ‚úÖ **Emotion expression** ‚Üí C√≥ c·∫£m x√∫c
- ‚úÖ **Speaking rate** ‚Üí T·ªëc ƒë·ªô n√≥i linh ho·∫°t
- ‚ö†Ô∏è **Slower** (1000ms) ‚Üí Trade-off v·ªõi ch·∫•t l∆∞·ª£ng

**Quality score**: ‚≠ê‚≠ê‚≠ê‚≠ê (85/100)
- Professional quality
- G·∫ßn nh∆∞ natural human voice

---

## üõ†Ô∏è Solutions & Implementations

### Solution 1Ô∏è‚É£: Intelligent Sentence Segmentation

#### A. Using PhoWhisper Timestamps + Rule-Based
```python
class IntelligentSegmenter:
    """
    K·∫øt h·ª£p timestamps + rules ƒë·ªÉ t√°ch c√¢u ch√≠nh x√°c
    """
    
    def __init__(self):
        # Vietnamese sentence ending markers
        self.sentence_enders = ['.', '!', '?', '„ÄÇ', 'ÔºÅ', 'Ôºü']
        
        # Pause thresholds
        self.min_pause_duration = 0.5  # 500ms
        self.sentence_pause_duration = 1.0  # 1s
        
    def segment_sentences(self, transcription_with_timestamps):
        """
        Input: [(start, end, word), ...]
        Output: [sentence1, sentence2, ...]
        """
        sentences = []
        current_sentence = []
        last_end_time = 0
        
        for start, end, word in transcription_with_timestamps:
            # Detect long pause
            pause_duration = start - last_end_time
            
            if pause_duration > self.sentence_pause_duration:
                # Long pause ‚Üí new sentence
                if current_sentence:
                    sentences.append(" ".join(current_sentence))
                    current_sentence = []
            
            current_sentence.append(word)
            
            # Check if word ends sentence (has punctuation)
            if any(word.endswith(p) for p in self.sentence_enders):
                sentences.append(" ".join(current_sentence))
                current_sentence = []
            
            last_end_time = end
        
        # Add remaining
        if current_sentence:
            sentences.append(" ".join(current_sentence))
        
        return sentences

# Usage:
segmenter = IntelligentSegmenter()
sentences = segmenter.segment_sentences(phowhisper_output)
```

**ƒê·ªô ch√≠nh x√°c**: ‚≠ê‚≠ê‚≠ê‚≠ê (80-85%)

#### B. Using NLP-based Sentence Boundary Detection
```python
from transformers import pipeline

# Vietnamese sentence segmentation model
segmenter = pipeline(
    "token-classification",
    model="NlpHUST/ner-vietnamese-electra-base"  # Can be adapted
)

def segment_with_nlp(text):
    """
    Use NLP model to detect sentence boundaries
    More accurate than rule-based
    """
    # Detect sentence boundaries using NLP
    # This requires a specialized model
    pass
```

**ƒê·ªô ch√≠nh x√°c**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (90-95%) - N·∫øu c√≥ model trained

---

### Solution 2Ô∏è‚É£: Prosody-Aware Translation

```python
class ProsodyAwareTranslator:
    """
    Preserve prosody information through translation pipeline
    """
    
    def __init__(self):
        self.translator = NLLBTranslator()
        
    def translate_with_prosody_hints(self, sentence, metadata):
        """
        Add prosody hints to translation
        
        Args:
            sentence: "B·∫°n ƒë·∫øn r·ªìi √†?"
            metadata: {
                'is_question': True,
                'emotion': 'curious',
                'emphasis_words': ['ƒë·∫øn']
            }
        """
        # Translate
        translated = self.translator.translate(sentence)
        
        # Add prosody metadata for TTS
        prosody_hints = {
            'text': translated,
            'pitch_pattern': 'rising' if metadata['is_question'] else 'falling',
            'emphasis_indices': self.map_emphasis_words(
                metadata['emphasis_words'], 
                sentence, 
                translated
            ),
            'emotion': metadata['emotion']
        }
        
        return prosody_hints

# Usage:
translator = ProsodyAwareTranslator()
result = translator.translate_with_prosody_hints(
    "B·∫°n ƒë·∫øn r·ªìi √†?",
    metadata={'is_question': True, 'emotion': 'curious'}
)

# Pass to TTS with prosody control
tts.synthesize(**result)
```

---

### Solution 3Ô∏è‚É£: Neural TTS with Prosody Control

#### Implementation v·ªõi F5-TTS-Vietnamese
```python
class VietnameseTTSWithProsody:
    """
    High-quality Vietnamese TTS with prosody control
    """
    
    def __init__(self):
        self.model = F5TTS.from_pretrained(
            "hynt/F5-TTS-Vietnamese-ViVoice"
        )
        
    def synthesize_with_prosody(
        self, 
        text, 
        prosody_hints=None
    ):
        """
        Generate natural Vietnamese speech
        
        Args:
            text: "B·∫°n ƒë·∫øn r·ªìi √†?"
            prosody_hints: {
                'pitch_pattern': 'rising',
                'emotion': 'curious',
                'speaking_rate': 1.0
            }
        """
        # Default prosody for Vietnamese
        config = {
            'speaking_rate': 1.0,
            'pitch_scale': 1.0,
            'energy_scale': 1.0
        }
        
        if prosody_hints:
            # Adjust based on hints
            if prosody_hints.get('pitch_pattern') == 'rising':
                config['pitch_scale'] = 1.2  # Raise pitch for questions
            
            if prosody_hints.get('emotion') == 'excited':
                config['speaking_rate'] = 1.1  # Faster
                config['energy_scale'] = 1.2   # More energy
            
            elif prosody_hints.get('emotion') == 'sad':
                config['speaking_rate'] = 0.9  # Slower
                config['pitch_scale'] = 0.9    # Lower pitch
        
        # Synthesize
        audio = self.model.synthesize(text, **config)
        
        return audio
```

---

## üìä Extended TTS Models Comparison

### STT Models (Reference)
| Feature | faster-whisper | PhoWhisper | 
|---------|---------------|------------|
| **Sentence Segmentation** | ‚≠ê‚≠ê VAD only | ‚≠ê‚≠ê‚≠ê‚≠ê Timestamps + Punct |
| **Punctuation** | ‚ùå Manual | ‚úÖ Automatic |
| **Vietnamese Quality** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Latency** | 600ms | 600ms |
| **License** | Apache 2.0 | BSD-3 |

### TTS Models (Complete Comparison)

| Feature | gTTS | **XTTS-v2** ‚≠ê | F5-TTS-Viet | Bark | SpeechT5 | MeloTTS | SeamlessM4T |
|---------|------|--------------|-------------|------|----------|---------|-------------|
| **Voice Cloning** | ‚ùå None | ‚úÖ **Excellent** | ‚úÖ Good | ‚úÖ Limited | ‚ùå None | ‚ùå None | ‚úÖ Preserves |
| **Pitch Control** | ‚ùå None | ‚úÖ **Full** | ‚úÖ Full | ‚ö†Ô∏è Limited | ‚ö†Ô∏è Limited | ‚úÖ Full | ‚úÖ Preserves |
| **Prosody** | ‚ùå None | ‚úÖ **Natural** | ‚úÖ Natural | ‚úÖ Natural | ‚ö†Ô∏è Basic | ‚úÖ Good | ‚úÖ Perfect |
| **Emotion** | ‚ùå None | ‚úÖ **Voice-based** | ‚ö†Ô∏è Limited | ‚úÖ Text-based | ‚ùå None | ‚ö†Ô∏è Limited | ‚úÖ Preserves |
| **Multilingual** | ‚úÖ 60+ | ‚úÖ **17 langs** | ‚ùå VI only | ‚úÖ 13 langs | ‚ùå EN only | ‚úÖ Per-lang | ‚úÖ 100+ |
| **Vietnamese** | ‚≠ê‚≠ê OK | ‚≠ê‚≠ê‚≠ê **Good** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚ùå No VI | ‚ùå No VI | ‚ùå No VI | ‚≠ê‚≠ê‚≠ê‚≠ê Very good |
| **Quality** | ‚≠ê‚≠ê (40/100) | ‚≠ê‚≠ê‚≠ê‚≠ê **(85/100)** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (95/100) | ‚≠ê‚≠ê‚≠ê‚≠ê (80/100) | ‚≠ê‚≠ê‚≠ê (70/100) | ‚≠ê‚≠ê‚≠ê (75/100) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (95/100) |
| **Latency (CPU)** | ‚úÖ 300ms | ‚ö†Ô∏è **800-1000ms** | ‚ö†Ô∏è 1000ms | ‚ùå 2000ms+ | ‚úÖ 500ms | ‚úÖ 400ms | ‚ùå 1500ms+ |
| **CPU-Friendly** | ‚úÖ Yes | ‚úÖ **Yes** | ‚úÖ Yes | ‚ö†Ô∏è Slow | ‚úÖ Yes | ‚úÖ Yes | ‚ùå Needs GPU |
| **RAM Usage** | ‚úÖ <100MB | ‚ö†Ô∏è **1-2GB** | ‚ö†Ô∏è 1.5-2GB | ‚ùå 3-4GB | ‚ö†Ô∏è 500MB | ‚ö†Ô∏è 800MB | ‚ùå 8GB+ |
| **License** | ‚úÖ Free | ‚ö†Ô∏è **Coqui Public** | ‚ö†Ô∏è CC-BY-NC-SA | ‚úÖ MIT | ‚úÖ MIT | ‚úÖ MIT | ‚ö†Ô∏è CC-BY-NC |
| **Downloads** | N/A | üî• **35.7M** | 4.6K | 1.8M | 4.9M | 210K | 69.8K |
| **Model Size** | Tiny | **Medium** | Large | Very Large | Medium | Medium | Very Large |
| **Setup Complexity** | ‚úÖ Simple | ‚ö†Ô∏è **Medium** | ‚ö†Ô∏è Complex | ‚ö†Ô∏è Medium | ‚úÖ Simple | ‚úÖ Simple | ‚ùå Complex |

### üéØ Key Findings:

#### **XTTS-v2 (Coqui)** - BEST BALANCE ‚≠ê
- ‚úÖ **Voice cloning** v·ªõi ch·ªâ 6-10s audio sample
- ‚úÖ **17 languages** bao g·ªìm Vietnamese
- ‚úÖ **CPU-friendly** (slower but runs on CPU)
- ‚úÖ **Natural prosody** inherited from voice sample
- ‚úÖ **MPL 2.0-like license** (Coqui Public License)
- ‚ö†Ô∏è **800-1000ms latency** (acceptable)
- ‚ö†Ô∏è **1-2GB RAM** (manageable)
- üî• **35.7M downloads** (most popular TTS)

#### **F5-TTS-Vietnamese** - BEST VIETNAMESE ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- ‚úÖ **Vietnamese-specialized** (trained on ViVoice dataset)
- ‚úÖ **Highest quality** for Vietnamese
- ‚ùå **Vietnamese ONLY** (not multilingual)
- ‚ö†Ô∏è **Non-commercial license**

#### **Bark (Suno)** - MOST EXPRESSIVE
- ‚úÖ **Best emotion** (laughs, sighs, music)
- ‚úÖ **MIT license** (commercial-friendly)
- ‚ùå **Too slow** for real-time (2s+)
- ‚ùå **No Vietnamese** support

#### **SpeechT5 (Microsoft)** - LIGHTWEIGHT
- ‚úÖ **MIT license**
- ‚úÖ **Fast** (500ms)
- ‚ùå **English only**
- ‚ùå **No prosody control**

#### **SeamlessM4T** - ULTIMATE (GPU Required)
- ‚úÖ **Perfect prosody preservation**
- ‚úÖ **100+ languages**
- ‚ùå **Needs GPU** (not suitable for CPU setup)
- ‚ùå **Very large** (8GB+ RAM)

---

## üéØ RECOMMENDED SOLUTION (UPDATED)

### Phase 3.1 (MVP - Current) ‚ö°
```yaml
STT: 
  - Model: vinai/PhoWhisper-small ‚úÖ
  - Features: Word timestamps + automatic punctuation
  - Segmentation: Timestamps + 500ms pause threshold
  
Translation:
  - Model: facebook/nllb-200-distilled-600M ‚úÖ
  - Input: Properly segmented sentences
  - Metadata: Preserve question marks, emphasis
  
TTS:
  - Model: gTTS (fast mode) ‚ö†Ô∏è
  - Quality: Basic (acceptable for MVP)
  - Latency: 300ms ‚úÖ
  - Trade-off: Robotic voice but FAST

Total E2E: ~1.1s ‚úÖ
Quality: ‚≠ê‚≠ê‚≠ê (Good enough for demo)
Deployment: Immediate
```

### Phase 3.2 (Balanced Quality) ‚≠ê **RECOMMENDED**
```yaml
STT: 
  - Keep PhoWhisper-small ‚úÖ
  - Add: Intelligent sentence segmenter
  
Translation:
  - Keep NLLB-200 ‚úÖ
  - Add: Prosody-aware wrapper
  
TTS - DUAL SYSTEM:
  - Primary: coqui/XTTS-v2 üé≠
    - Voice cloning: 6-10s sample
    - Multilingual: 17 languages (incl. Vietnamese)
    - Prosody: Natural from voice sample
    - Latency: 800-1000ms
    - Quality: ‚≠ê‚≠ê‚≠ê‚≠ê (85/100)
    
  - Fallback: gTTS ‚ö°
    - Fast mode for real-time
    - Latency: 300ms
    - Quality: ‚≠ê‚≠ê (40/100)
  
  - User Toggle: Fast ‚ö° / Quality üé≠ / Custom Voice üé§

Total E2E: 
  - Fast mode: 1.1s ‚úÖ
  - Quality mode: 1.8s ‚ö†Ô∏è (slightly over)
  - Custom voice: 1.8s + 10s setup ‚ö†Ô∏è

Quality: ‚≠ê‚≠ê‚≠ê‚≠ê (Production-ready)
Deployment: 1-2 weeks
```

### Phase 3.3 (Vietnamese-Optimized) üáªüá≥
```yaml
STT: 
  - Keep PhoWhisper-small ‚úÖ
  
Translation:
  - Keep NLLB-200 ‚úÖ
  
TTS - TRIPLE SYSTEM:
  - Fast: gTTS (300ms) ‚ö°
  - Quality: XTTS-v2 (1000ms) üé≠
  - Vietnamese Pro: F5-TTS-Vietnamese (1000ms) üáªüá≥
    - BEST Vietnamese quality
    - Natural prosody and tones
    - Specialized for Vietnamese only
    
  - User Toggle: Fast / Multilingual / Vietnamese Pro

Total E2E: 1.1s / 1.8s / 1.8s
Quality: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Best Vietnamese experience)
Deployment: 3-4 weeks
Trade-off: More complex, license restrictions
```

### Phase 3.4 (Commercial Production) üíº
```yaml
If need full commercial license:

STT: vinai/PhoWhisper-small (BSD-3 ‚úÖ)
Translation: google/madlad400-3b-mt (Apache 2.0 ‚úÖ)
TTS: 
  - Primary: coqui/XTTS-v2 (Coqui Public ‚úÖ)
  - OR: Bark (MIT ‚úÖ) - slower but commercial
  - OR: MeloTTS (MIT ‚úÖ) - fast but no Vietnamese
  
All commercial-friendly licenses ‚úÖ
Trade-off: Larger models, higher resource usage
```

### Phase 3.X (Ultimate - GPU Required) üöÄ
```yaml
Consider: Meta's SeamlessM4T-v2
  - Integrated: STT + Translation + TTS
  - Preserves: Prosody, pitch, emotion end-to-end
  - Features: "SeamlessExpressive" mode
  - Quality: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê State-of-the-art
  - Trade-off: 
    - Requires GPU (not suitable for current CPU setup)
    - Very large model (8GB+ RAM)
    - Non-commercial license
    - Complex setup

Verdict: NOT suitable for current infrastructure
Revisit when upgrade to GPU instances
```

---

## üÜö Head-to-Head: XTTS-v2 vs F5-TTS-Vietnamese

### XTTS-v2 Advantages ‚úÖ
1. **Multilingual** (17 languages) ‚Üí Can handle English output too
2. **Voice cloning** ‚Üí Clone user's voice for personalization
3. **More mature** (35.7M downloads, production-proven)
4. **Better license** (Coqui Public ~ MPL 2.0)
5. **Easier setup** (simpler integration)
6. **Active community** (more examples, support)

### F5-TTS-Vietnamese Advantages ‚úÖ
1. **Vietnamese-specialized** ‚Üí Best quality for Vietnamese
2. **Natural tones** ‚Üí Perfect Vietnamese tone marks
3. **Trained on ViVoice** ‚Üí High-quality Vietnamese dataset
4. **Newer architecture** ‚Üí More advanced F5 model

### Side-by-Side Example

**Input**: "Xin ch√†o! B·∫°n kh·ªèe kh√¥ng?" (Hello! How are you?)

**gTTS** (Current):
```
Audio: "sin cao ban koe kong" 
Quality: ‚≠ê‚≠ê (40/100)
Issues: Robotic, no emotion, flat tones
Latency: 300ms ‚úÖ
```

**XTTS-v2** (Recommended):
```
Audio: "Xin ch√†o! B·∫°n kh·ªèe kh√¥ng?" (with natural intonation)
Quality: ‚≠ê‚≠ê‚≠ê‚≠ê (85/100)
Features: 
  - Natural prosody ‚úÖ
  - Rising tone on "kh√¥ng?" ‚úÖ
  - Emotion preserved ‚úÖ
  - Can clone voice ‚úÖ
Latency: 900ms ‚ö†Ô∏è
```

**F5-TTS-Vietnamese** (Best VI):
```
Audio: "Xin ch√†o! B·∫°n kh·ªèe kh√¥ng?" (perfect Vietnamese)
Quality: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (95/100)
Features:
  - Perfect Vietnamese tones ‚úÖ‚úÖ
  - Natural prosody ‚úÖ
  - Best for Vietnamese ONLY ‚ö†Ô∏è
Latency: 1000ms ‚ö†Ô∏è
```

---

## üí° XTTS-v2 Implementation Details

### Quick Start Example
```python
from TTS.api import TTS

# Initialize XTTS-v2
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# Option 1: Use default voice
audio = tts.tts(
    text="Xin ch√†o! B·∫°n kh·ªèe kh√¥ng?",
    language="vi"  # Vietnamese
)

# Option 2: Clone user's voice
audio = tts.tts(
    text="Xin ch√†o! B·∫°n kh·ªèe kh√¥ng?",
    speaker_wav="user_voice_sample.wav",  # 6-10s sample
    language="vi"
)

# Save audio
tts.tts_to_file(
    text="Xin ch√†o!",
    speaker_wav="user_voice.wav",
    language="vi",
    file_path="output.wav"
)
```

### Performance on CPU
```yaml
Hardware: c2d-highcpu-8 (8 vCPUs, 16GB RAM)

Benchmarks:
  - Short text (10 words): 800ms
  - Medium text (30 words): 1000ms
  - Long text (50+ words): 1200-1500ms

RAM Usage:
  - Model load: 1.2GB
  - Inference: +300MB
  - Total: ~1.5GB

CPU Usage:
  - During synthesis: 80-90% (1 core)
  - Idle: <5%

Optimization:
  - Use batch processing
  - Cache frequently used phrases
  - Preload model at startup
```

### Supported Languages (17)
```python
XTTS_V2_LANGUAGES = [
    'en',  # English ‚úÖ
    'es',  # Spanish ‚úÖ
    'fr',  # French ‚úÖ
    'de',  # German ‚úÖ
    'it',  # Italian ‚úÖ
    'pt',  # Portuguese ‚úÖ
    'pl',  # Polish ‚úÖ
    'tr',  # Turkish ‚úÖ
    'ru',  # Russian ‚úÖ
    'nl',  # Dutch ‚úÖ
    'cs',  # Czech ‚úÖ
    'ar',  # Arabic ‚úÖ
    'zh-cn',  # Chinese (Simplified) ‚úÖ
    'ja',  # Japanese ‚úÖ
    'ko',  # Korean ‚úÖ
    'hu',  # Hungarian ‚úÖ
    'vi'   # Vietnamese ‚úÖ‚úÖ‚úÖ
]
```

### Voice Cloning Requirements
```yaml
Sample Audio:
  - Duration: 6-10 seconds (optimal)
  - Format: WAV, MP3, FLAC
  - Quality: 16kHz+ sample rate
  - Content: Clear speech, minimal noise
  - Language: Match target language

Example:
  User speaks: "Xin ch√†o, t√¥i l√† John. R·∫•t vui ƒë∆∞·ª£c g·∫∑p b·∫°n."
  Duration: ~8 seconds
  ‚Üí System clones John's voice
  ‚Üí All future TTS uses John's voice characteristics
```

### Integration with Current System
```python
class DualTTSSystem:
    """
    Intelligent TTS with fast/quality modes
    """
    
    def __init__(self):
        # Fast TTS (always loaded)
        self.fast_tts = gTTS
        
        # Quality TTS (lazy load)
        self.xtts = None
        self.xtts_loaded = False
        
        # User preferences
        self.default_mode = "fast"  # or "quality"
        self.user_voice_samples = {}
    
    def synthesize(
        self, 
        text: str, 
        language: str = "vi",
        mode: str = None,
        user_id: str = None
    ):
        """
        Synthesize speech with mode selection
        """
        mode = mode or self.default_mode
        
        if mode == "fast":
            # Use gTTS (300ms)
            return self.fast_synthesize(text, language)
        
        elif mode == "quality":
            # Load XTTS if needed
            if not self.xtts_loaded:
                self.load_xtts()
            
            # Use XTTS-v2 (900ms)
            return self.xtts_synthesize(text, language)
        
        elif mode == "custom" and user_id:
            # Use cloned voice
            voice_sample = self.user_voice_samples.get(user_id)
            if voice_sample:
                return self.xtts_synthesize(
                    text, 
                    language, 
                    speaker_wav=voice_sample
                )
            else:
                # Fallback to quality mode
                return self.xtts_synthesize(text, language)
    
    def load_xtts(self):
        """Lazy load XTTS-v2 to save RAM"""
        from TTS.api import TTS
        self.xtts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
        self.xtts_loaded = True
        logger.info("XTTS-v2 loaded successfully")
    
    def add_user_voice(self, user_id: str, audio_sample: bytes):
        """Register user voice sample for cloning"""
        # Save sample
        sample_path = f"/tmp/voices/{user_id}.wav"
        with open(sample_path, 'wb') as f:
            f.write(audio_sample)
        
        self.user_voice_samples[user_id] = sample_path
        logger.info(f"Voice sample registered for user {user_id}")
```

---

## üöÄ Implementation Priority

### üî¥ URGENT (This week):
1. ‚úÖ Implement intelligent sentence segmenter
   - Use PhoWhisper timestamps
   - Add 500ms-1s pause threshold
   - Preserve punctuation from model

2. ‚úÖ Fix translation input
   - Ensure sentences are complete before translating
   - Add batch sentence translation

### üü° HIGH (Next 2 weeks):
3. ‚è≥ Integrate F5-TTS-Vietnamese
   - Dual TTS system (fast/quality modes)
   - Basic prosody control

4. ‚è≥ Add prosody metadata pipeline
   - Extract from STT
   - Pass through translation
   - Apply to TTS

### üü¢ MEDIUM (Phase 3.2):
5. ‚è≥ Advanced prosody features
   - Emotion detection
   - Emphasis tracking
   - Natural pauses

---

## üí° Quick Wins (Can implement today)

### 1. Intelligent Pause Detection
```python
# Add to STT service
def detect_sentence_boundaries(word_timestamps, min_pause=0.5):
    sentences = []
    current = []
    
    for i, (start, end, word) in enumerate(word_timestamps):
        current.append(word)
        
        # Check next word pause
        if i < len(word_timestamps) - 1:
            next_start = word_timestamps[i+1][0]
            pause = next_start - end
            
            if pause > min_pause or word.endswith(('.', '!', '?')):
                sentences.append(" ".join(current))
                current = []
    
    return sentences
```

### 2. Question Detection for TTS
```python
# Add prosody hint
def add_prosody_hint(text):
    if text.endswith('?'):
        return {
            'text': text,
            'pitch_adjustment': +0.2,  # Raise pitch 20%
            'emphasis': 'end'
        }
    return {'text': text}
```

---

## üìù Summary

**C√ÇU TR·∫¢ L·ªúI CHO NG∆Ø·ªúI D√ôNG**:

‚úÖ **Ng·∫Øt ngh·ªâ c√¢u**: 
- PhoWhisper-small C√ì word timestamps v√† automatic punctuation
- C·∫¶N th√™m intelligent segmenter (500ms pause threshold)
- ƒê·ªô ch√≠nh x√°c: 80-85% (r·∫•t t·ªët)

‚ö†Ô∏è **Cao ƒë·ªô gi·ªçng n√≥i (Pitch)**:
- gTTS KH√îNG h·ªó tr·ª£ pitch control ‚Üí Gi·ªçng ph·∫≥ng, robot ‚ùå
- F5-TTS-Vietnamese C√ì full pitch control ‚Üí T·ª± nhi√™n ‚úÖ
- RECOMMENDED: Upgrade to F5-TTS trong Phase 3.2

‚ö†Ô∏è **Ng·ªØ ƒëi·ªáu (Prosody)**:
- gTTS KH√îNG c√≥ prosody ‚Üí Thi·∫øu c·∫£m x√∫c ‚ùå
- F5-TTS C√ì natural prosody + emotion ‚úÖ
- Trade-off: +700ms latency nh∆∞ng quality tƒÉng 70%

**üéØ RECOMMENDATION**:
1. **MVP (hi·ªán t·∫°i)**: Keep gTTS, add intelligent segmenter
2. **Production (2 tu·∫ßn)**: Add F5-TTS v·ªõi dual mode (fast/quality)
3. **Long-term**: Consider SeamlessM4T n·∫øu upgrade GPU

B·∫°n mu·ªën t√¥i implement intelligent segmenter ngay b√¢y gi·ªù kh√¥ng? üöÄ
