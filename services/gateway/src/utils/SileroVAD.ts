/**
 * SileroVAD Processor - Voice Activity Detection cho Vietnamese
 *
 * Production integration v·ªõi avr-vad (RealTimeVAD)
 * - RealTimeVAD.new(options?: Partial<RealTimeVADOptions>): Promise<RealTimeVAD>
 * - RealTimeVAD.processAudio(audio: Float32Array): Promise<void>
 * - Emits callbacks: onSpeechStart / onSpeechEnd / onFrameProcessed / onVADMisfire
 *
 * ·ªû ƒë√¢y ta:
 * - Feed audio theo t·ª´ng chunk PCM16 (sau n√†y c√≥ th·ªÉ th√™m resample n·∫øu kh√¥ng ph·∫£i 16kHz)
 * - Gom c√°c ƒëo·∫°n speech th√†nh utterance b·∫±ng callback onSpeechEnd
 * - D√πng VAD ƒë·ªÉ gi·∫£m s·ªë l·∫ßn g·ªçi STT
 */

import { logger } from '../logger';

export class SileroVADProcessor {
  // Th·ª±c th·ªÉ RealTimeVAD t·ª´ avr-vad
  private vad: import('avr-vad').RealTimeVAD | null = null;

  // Buffer v√† state cho utterance hi·ªán t·∫°i (PCM16)
  private speechBuffers: Buffer[] = [];
  private isSpeaking = false;

  // Stats ƒë∆°n gi·∫£n cho monitoring
  private totalUtterances = 0;

  // VAD config (tune cho ti·∫øng Vi·ªát ‚Äì c√≥ th·ªÉ ch·ªânh th√™m sau)
  private readonly POSITIVE_THRESHOLD = 0.6;
  private readonly NEGATIVE_THRESHOLD = 0.4;
  private readonly REDEMPTION_FRAMES = 5;
  private readonly MIN_SPEECH_FRAMES = 3;

  async initialize(): Promise<void> {
    try {
      const { RealTimeVAD, getDefaultRealTimeVADOptions } = await import('avr-vad');

      const baseOptions = getDefaultRealTimeVADOptions('v5');

      this.vad = await RealTimeVAD.new({
        ...baseOptions,
        sampleRate: 16000, // gateway s·∫Ω c·∫ßn ƒë·∫£m b·∫£o audio g·ª≠i v√†o l√† 16kHz ho·∫∑c d√πng Resampler ·ªü layer tr√™n
        positiveSpeechThreshold: this.POSITIVE_THRESHOLD,
        negativeSpeechThreshold: this.NEGATIVE_THRESHOLD,
        redemptionFrames: this.REDEMPTION_FRAMES,
        minSpeechFrames: this.MIN_SPEECH_FRAMES,
        submitUserSpeechOnPause: true,

        // Callbacks
        onFrameProcessed: (probs) => {
          // C√≥ th·ªÉ log chi ti·∫øt n·∫øu c·∫ßn debug
          // logger.debug('VAD frame', probs);
        },
        onVADMisfire: () => {
          logger.debug('‚ö†Ô∏è VAD misfire (segment ng·∫Øn / noise)');
        },
        onSpeechStart: () => {
          this.isSpeaking = true;
          this.speechBuffers = [];
          logger.debug('üé§ Speech start detected');
        },
        onSpeechRealStart: () => {
          logger.debug('üéØ Speech real start');
        },
        onSpeechEnd: (audio: Float32Array) => {
          // RealTimeVAD tr·∫£ v·ªÅ Float32Array @16kHz; ta convert sang Buffer PCM16
          const pcm16 = this.float32ToPcm16(audio);
          this.speechBuffers.push(pcm16);
          this.isSpeaking = false;
          this.totalUtterances += 1;
          logger.debug('üìù Speech end detected', {
            durationMs: Math.round((audio.length / 16000) * 1000),
          });
        },
      });

      this.vad.start();

      logger.info('‚úÖ AVR-VAD RealTimeVAD initialized', {
        positiveThreshold: this.POSITIVE_THRESHOLD,
        negativeThreshold: this.NEGATIVE_THRESHOLD,
        redemptionFrames: this.REDEMPTION_FRAMES,
        minSpeechFrames: this.MIN_SPEECH_FRAMES,
      });
    } catch (error) {
      logger.error('‚ùå Failed to initialize AVR-VAD:', error);
      this.vad = null;
    }
  }

  /**
   * X·ª≠ l√Ω m·ªôt chunk PCM16 (gi·∫£ s·ª≠ sampleRate ƒë√£ l√† 16kHz ho·∫∑c gateway ƒë√£ resample tr∆∞·ªõc ƒë√≥).
   * Tr·∫£ v·ªÅ 1 utterance n·∫øu VAD v·ª´a k·∫øt th√∫c ƒëo·∫°n speech; n·∫øu ch∆∞a c√≥ ƒëo·∫°n ho√†n ch·ªânh th√¨ hasUtterance=false.
   */
  async processChunk(audioChunk: Buffer): Promise<{
    hasUtterance: boolean;
    utteranceAudio: Buffer | null;
    isSpeaking: boolean;
  }> {
    if (!this.vad) {
      // Fallback: kh√¥ng c√≥ VAD ‚Üí g·ª≠i th·∫≥ng sang STT
      return { hasUtterance: true, utteranceAudio: audioChunk, isSpeaking: true };
    }

    try {
      const float32 = this.bufferToFloat32(audioChunk);
      await this.vad.processAudio(float32);

      // N·∫øu onSpeechEnd ƒë√£ ƒë∆∞·ª£c g·ªçi trong khi processAudio, speechBuffers s·∫Ω ch·ª©a 1 utterance ho√†n ch·ªânh
      if (!this.isSpeaking && this.speechBuffers.length > 0) {
        const utterance = Buffer.concat(this.speechBuffers);
        this.speechBuffers = [];
        return { hasUtterance: true, utteranceAudio: utterance, isSpeaking: false };
      }

      // ƒêang trong ƒëo·∫°n speech ho·∫∑c ch∆∞a ƒë·ªß d√†i ƒë·ªÉ k·∫øt th√∫c
      return { hasUtterance: false, utteranceAudio: null, isSpeaking: this.isSpeaking };
    } catch (error) {
      logger.error('VAD Error in processChunk:', error);
      // Fallback: n·∫øu VAD l·ªói runtime, v·∫´n cho audio ƒëi ti·∫øp
      return { hasUtterance: true, utteranceAudio: audioChunk, isSpeaking: true };
    }
  }

  private bufferToFloat32(buffer: Buffer): Float32Array {
    const int16Array = new Int16Array(buffer.buffer, buffer.byteOffset, buffer.length / 2);
    const float32Array = new Float32Array(int16Array.length);
    for (let i = 0; i < int16Array.length; i++) {
      float32Array[i] = int16Array[i] / 32768.0;
    }
    return float32Array;
  }

  private float32ToPcm16(data: Float32Array): Buffer {
    const int16 = new Int16Array(data.length);
    for (let i = 0; i < data.length; i++) {
      let s = data[i];
      s = Math.max(-1, Math.min(1, s));
      int16[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
    return Buffer.from(int16.buffer);
  }

  flush(): Buffer | null {
    if (this.speechBuffers.length > 0) {
      const buf = Buffer.concat(this.speechBuffers);
      this.speechBuffers = [];
      this.isSpeaking = false;
      return buf;
    }
    return null;
  }

  reset(): void {
    this.speechBuffers = [];
    this.isSpeaking = false;
    this.vad?.reset();
  }

  getStats() {
    return {
      isSpeaking: this.isSpeaking,
      bufferedChunks: this.speechBuffers.length,
      totalUtterances: this.totalUtterances,
    };
  }
}
