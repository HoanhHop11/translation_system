# ==============================================================================
# JBCALLING TRANSLATION REALTIME - OPTIMIZED STACK CONFIG
# ==============================================================================
# 
# KIẾN TRÚC 3-NODE TỐI ƯU CHO WORKLOAD:
#
# translation01 (Manager - 4 cores, 30GB RAM, 96GB disk):
#   - Translation service (NLLB - compute-heavy, 1.5GB RAM)
#   - Monitoring stack (Prometheus, Grafana, Loki)
#   - Traefik (load balancer)
#   - Redis (shared state)
#
# translation02 (Worker - 4 cores, 15GB RAM, 96GB disk):
#   - STT service (PhoWhisper - memory-heavy, 3.8GB RAM)
#   - Gateway service (MediaSoup - CPU-intensive continuous)
#   - TTS service 1 replica (synthesis workload)
#
# translation03 (Worker - 4 cores, 15GB RAM, 48GB disk):
#   - API service (3 replicas - lightweight)
#   - Frontend (3 replicas - static files)
#   - Signaling (3 replicas - WebSocket)
#   - TTS service 1 replica (for redundancy)
#   - Demo
#
# ==============================================================================

version: '3.8'

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

# Production-ready update config - zero downtime deployment
x-update-config: &default-update-config
  parallelism: 1          # Update 1 task at a time
  delay: 10s              # Wait 10s between updates
  failure_action: rollback
  monitor: 15s            # Monitor 15s for failures
  max_failure_ratio: 0.3  # Rollback if >30% fail
  order: start-first      # Start new before stopping old (zero downtime)

x-rollback-config: &default-rollback-config
  parallelism: 1
  delay: 5s
  failure_action: pause
  monitor: 10s
  order: stop-first

x-restart-policy: &default-restart-policy
  condition: on-failure
  delay: 5s
  max_attempts: 3
  window: 120s

networks:
  frontend:
    driver: overlay
    attachable: true
  backend:
    driver: overlay
    attachable: true
  monitoring:
    driver: overlay
    attachable: true

volumes:
  models_cache:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
  traefik_certs:
    driver: local
  redis_data:
    driver: local

services:
  # ===========================================================================
  # TRANSLATION01 - MANAGER NODE (4 cores, 30GB RAM)
  # ===========================================================================
  
  # Traefik - Reverse Proxy / Load Balancer
  # Deploy: translation01 (manager node, needs Docker socket access)
  traefik:
    image: traefik:v3.0
    command:
      # API và Dashboard
      - "--api.dashboard=true"
      - "--api.insecure=false"
      
      # Entrypoints
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.web.http.redirections.entryPoint.to=websecure"
      - "--entrypoints.web.http.redirections.entryPoint.scheme=https"
      - "--entrypoints.websecure.http.tls.certResolver=letsencrypt"
      
      # WebSocket entrypoint
      - "--entrypoints.websocket.address=:8001"
      
      # Docker Swarm provider (v3 syntax)
      - "--providers.swarm=true"
      - "--providers.swarm.endpoint=unix:///var/run/docker.sock"
      - "--providers.swarm.exposedbydefault=false"
      # NOTE: Không set global network, để services tự specify qua labels
      - "--providers.swarm.watch=true"
      
      # API & Ping
      - "--ping=true"
      
      # Let's Encrypt - TLS-ALPN-01 Challenge (port 443, không bị rate limit theo domain)
      - "--certificatesresolvers.letsencrypt.acme.email=hopboy2003@gmail.com"
      - "--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json"
      - "--certificatesresolvers.letsencrypt.acme.tlschallenge=true"
      
      # Logging
      - "--log.level=INFO"
      - "--accesslog=true"
      
      # Metrics
      - "--metrics.prometheus=true"
      
    ports:
      - target: 80
        published: 80
        mode: host
      - target: 443
        published: 443
        mode: host
      - target: 8001
        published: 8001
        mode: host
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "traefik_certs:/letsencrypt"
    networks:
      - frontend
      - backend
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        - "traefik.enable=true"
        # Dashboard
        - "traefik.http.routers.dashboard.rule=Host(`traefik.jbcalling.site`)"
        - "traefik.http.routers.dashboard.service=api@internal"
        - "traefik.http.services.dashboard.loadbalancer.server.port=8080"
        # NOTE: Gateway routing giờ được config qua labels trên Gateway service (ingress mode)
    logging: *default-logging

  # Redis - Shared State & Cache
  # Deploy: translation01 (centralized state management)
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    networks:
      - backend
    volumes:
      - redis_data:/data
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation01
      resources:
        limits:
          cpus: '0.5'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 1G
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    logging: *default-logging

  # Redis for Gateway on translation02 - Lightweight cache for WebRTC state
  redis_gateway:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    networks:
      - backend  # Share network with Gateway
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation02
      resources:
        limits:
          cpus: '0.25'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    logging: *default-logging

  # Translation Service - NLLB Model
  # Deploy: translation01 (has most RAM - 30GB, compute-heavy workload)
  translation:
    image: jackboun11/jbcalling-translation:redis-cache
    networks:
      - backend
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_TTL=3600
      - MODEL_NAME=facebook/nllb-200-distilled-600M
      - TORCH_NUM_THREADS=3
      - OMP_NUM_THREADS=3
    volumes:
      - models_cache:/root/.cache/huggingface
    depends_on:
      - redis
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation01  # Nhiều RAM nhất
      resources:
        limits:
          cpus: '3.0'      # 3 cores cho NLLB inference
          memory: 6G       # 6GB RAM (hiện tại dùng 1.5GB, buffer cho peaks)
        reservations:
          cpus: '1.5'
          memory: 3G
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.translation.rule=Host(`api.jbcalling.site`) && PathPrefix(`/api/v1/translate`)"
        - "traefik.http.routers.translation.entrypoints=websecure"
        - "traefik.http.routers.translation.tls.certresolver=letsencrypt"
        - "traefik.http.services.translation.loadbalancer.server.port=8003"
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8003/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *default-logging

  # Prometheus - Metrics Collection
  # Deploy: translation01 (monitoring on manager node)
  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
    volumes:
      - prometheus_data:/prometheus
      # Use default Prometheus config for now
    networks:
      - monitoring
      - backend
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation01
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.prometheus.rule=Host(`prometheus.jbcalling.site`)"
        - "traefik.http.routers.prometheus.entrypoints=websecure"
        - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
        - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
    logging: *default-logging

  # Grafana - Monitoring Dashboard
  # Deploy: translation01
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_SERVER_ROOT_URL=https://grafana.jbcalling.site
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - monitoring
      - frontend
    depends_on:
      - prometheus
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation01
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.grafana.rule=Host(`grafana.jbcalling.site`)"
        - "traefik.http.routers.grafana.entrypoints=websecure"
        - "traefik.http.routers.grafana.tls.certresolver=letsencrypt"
        - "traefik.http.services.grafana.loadbalancer.server.port=3000"
    logging: *default-logging

  # Loki - Log Aggregation
  # Deploy: translation01
  loki:
    image: grafana/loki:latest
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki_data:/loki
    networks:
      - monitoring
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation01
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging: *default-logging

  # ===========================================================================
  # TRANSLATION02 - WORKER NODE (4 cores, 15GB RAM, 96GB disk)
  # Heavy AI Workloads: STT (memory-heavy) + Gateway (CPU-intensive) + TTS
  # ===========================================================================

  # STT Service - PhoWhisper (Memory-Heavy: 3.8GB RAM)
  # Deploy: translation02 (has 15GB RAM, dedicated for heavy AI)
  stt:
    image: jackboun11/jbcalling-stt:streaming-1.0.0
    networks:
      - backend
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MODEL_VI=vinai/PhoWhisper-small
      - MODEL_MULTI=openai/whisper-small
      - ENABLE_PUNCTUATION=true
      - TORCH_NUM_THREADS=2
    volumes:
      - models_cache:/root/.cache/huggingface
    depends_on:
      - redis
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1          # Chỉ 1 replica vì memory-heavy (3.8GB)
      placement:
        constraints:
          - node.labels.instance == translation02  # Dedicated for heavy AI
      resources:
        limits:
          cpus: '2.0'      # 2 cores cho Whisper inference
          memory: 6G       # 6GB RAM (hiện tại 3.8GB, buffer cho peaks)
        reservations:
          cpus: '1.0'
          memory: 4G
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.stt.rule=Host(`api.jbcalling.site`) && PathPrefix(`/api/v1/transcribe`)"
        - "traefik.http.routers.stt.entrypoints=websecure"
        - "traefik.http.routers.stt.tls.certresolver=letsencrypt"
        - "traefik.http.services.stt.loadbalancer.server.port=8002"
        # WebSocket support for streaming
        - "traefik.http.routers.stt-ws.rule=Host(`api.jbcalling.site`) && PathPrefix(`/api/v1/stream`)"
        - "traefik.http.routers.stt-ws.entrypoints=websocket"
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8002/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s  # PhoWhisper needs time to load
    logging: *default-logging

  # Gateway Service - MediaSoup WebRTC (CPU-Intensive Continuous)
  # Deploy: translation02 (dedicated node for WebRTC processing)
  # Access via https://webrtc.jbcalling.site (Traefik routing)
  gateway:
    image: jackboun11/jbcalling-gateway:1.0.1
    networks:
      - backend  # Backend network for Redis, STT access
      - frontend # Frontend network for Traefik routing (REQUIRED for service discovery)
    ports:
      - target: 3000
        published: 3000
        protocol: tcp
        mode: ingress  # Ingress mode cho Traefik service discovery
    environment:
      - PORT=3000
      - HOST=0.0.0.0
      - NODE_ENV=production
      - CORS_ORIGIN=https://jbcalling.site,https://webrtc.jbcalling.site
      - WORKER_COUNT=2     # 2 MediaSoup workers (có 4 cores total)
      - RTC_MIN_PORT=40000
      - RTC_MAX_PORT=40100
      - ANNOUNCED_IP=34.142.190.250  # translation02 public IP
      - LOG_LEVEL=warn
      - REDIS_HOST=redis_gateway      # Use service name in overlay network
      - REDIS_PORT=6379               # Default Redis port
      - STT_SERVICE_URL=http://stt:8002  # Use service name
      - ENABLE_AUDIO_PROCESSING=true
      - AUDIO_SAMPLE_RATE=48000
      - AUDIO_CHANNELS=1
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated  # Replicated mode cho Traefik service discovery
      replicas: 1       # 1 replica trên translation02
      placement:
        constraints:
          - node.labels.instance == translation02
      resources:
        limits:
          cpus: '1.5'      # 1.5 cores cho MediaSoup + RTP processing
          memory: 2G       # 2GB RAM cho Node.js + WebRTC state
        reservations:
          cpus: '0.75'
          memory: 1G
      labels:
        - "traefik.enable=true"
        - "traefik.swarm.network=translation_frontend"  # Swarm provider cần .swarm. không phải .docker.
        - "traefik.http.routers.gateway.rule=Host(`webrtc.jbcalling.site`)"
        - "traefik.http.routers.gateway.entrypoints=websecure"
        - "traefik.http.routers.gateway.tls.certresolver=letsencrypt"
        - "traefik.http.services.gateway.loadbalancer.server.port=3000"
        - "traefik.docker.lbswarm=true"  # Dùng Swarm VIP cho global mode service
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *default-logging

  # TTS Service - Coqui TTS (1 replica on translation02)
  # Deploy: translation02 (co-located with STT for pipeline efficiency)
  tts_translation02:
    image: jackboun11/jbcalling-tts:redis-cache
    networks:
      - backend
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_TTL=3600
      - TTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
      - TORCH_NUM_THREADS=1
    volumes:
      - models_cache:/root/.cache/TTS
    depends_on:
      - redis
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation02
      resources:
        limits:
          cpus: '0.5'      # 0.5 core (TTS nhẹ nhất: 142MB RAM, 0.2% CPU)
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.tts.rule=Host(`api.jbcalling.site`) && PathPrefix(`/api/v1/synthesize`)"
        - "traefik.http.routers.tts.entrypoints=websecure"
        - "traefik.http.routers.tts.tls.certresolver=letsencrypt"
        - "traefik.http.services.tts.loadbalancer.server.port=8004"
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8004/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *default-logging

  # ===========================================================================
  # TRANSLATION03 - WORKER NODE (4 cores, 15GB RAM, 48GB disk)
  # Lightweight Services: API, Frontend, Signaling, TTS replica, Demo
  # ===========================================================================

  # API Service - REST API (Lightweight: 40MB RAM, <0.1% CPU)
  # Deploy: translation03 (3 replicas cho high availability)
  api:
    image: jackboun11/jbcalling-api:1.0.0
    networks:
      - backend
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - STT_SERVICE_URL=http://stt:8002
      - TRANSLATION_SERVICE_URL=http://translation:8003
      - TTS_SERVICE_URL=http://tts:8004
      - CORS_ORIGINS=https://jbcalling.site
    depends_on:
      - redis
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 3      # 3 replicas cho load balancing
      placement:
        constraints:
          - node.labels.instance == translation03
      resources:
        limits:
          cpus: '0.25'   # Lightweight: 40MB RAM, <0.1% CPU
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.api.rule=Host(`api.jbcalling.site`) && PathPrefix(`/api/v1`)"
        - "traefik.http.routers.api.entrypoints=websecure"
        - "traefik.http.routers.api.tls.certresolver=letsencrypt"
        - "traefik.http.services.api.loadbalancer.server.port=8000"
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8000/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *default-logging

  # Frontend Service - React SPA (Production Build)
  # Deploy: translation03 (3 replicas for high availability)
  # Built with Vite + React, served via nginx (no proxy, static files only)
  frontend:
    image: jackboun11/jbcalling-frontend:1.0.9  # PRODUCTION với MediaSoup client integration
    networks:
      - frontend
    environment:
      - NODE_ENV=production
    deploy:
      # Custom update config cho static content service
      update_config:
        parallelism: 1
        delay: 5s              # Giảm delay vì static files start nhanh
        failure_action: rollback
        monitor: 45s           # Tăng từ 30s lên 45s để đảm bảo healthcheck pass
        max_failure_ratio: 0
        order: stop-first      # CRITICAL FIX: stop-first để tránh Swarm kill new task
      rollback_config:
        parallelism: 1
        delay: 0s
        failure_action: pause
        monitor: 10s
        order: stop-first
      restart_policy:
        condition: on-failure  # Chỉ restart on-failure, không phải "any"
        delay: 3s
        max_attempts: 5
        window: 60s
      mode: replicated
      replicas: 3
      placement:
        constraints:
          - node.labels.instance == translation03
      resources:
        limits:
          cpus: '0.2'    # Nginx serving static files
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 64M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.frontend.rule=Host(`jbcalling.site`) || Host(`www.jbcalling.site`)"
        - "traefik.http.routers.frontend.entrypoints=websecure"
        - "traefik.http.routers.frontend.tls.certresolver=letsencrypt"
        - "traefik.http.routers.frontend.tls.domains[0].main=jbcalling.site"
        - "traefik.http.routers.frontend.tls.domains[0].sans=www.jbcalling.site"
        - "traefik.http.services.frontend.loadbalancer.server.port=80"
    # Stop grace period - cho nginx time để graceful shutdown
    stop_grace_period: 30s
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 10s          # Check thường xuyên hơn
      timeout: 5s
      retries: 3
      start_period: 20s      # Tăng start_period để container có time khởi động
    logging: *default-logging

  # Signaling Service - WebSocket (Lightweight: 39MB RAM, <0.1% CPU)
  # Deploy: translation03 (3 replicas cho WebSocket HA)
  signaling:
    image: jackboun11/jbcalling-api:1.0.0
    command: ["uvicorn", "signaling:app", "--host", "0.0.0.0", "--port", "8001"]
    networks:
      - backend
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 3      # 3 replicas cho WebSocket load balancing
      placement:
        constraints:
          - node.labels.instance == translation03
      resources:
        limits:
          cpus: '0.25'   # Lightweight WebSocket: 39MB RAM
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.signaling.rule=Host(`api.jbcalling.site`) && PathPrefix(`/ws`)"
        - "traefik.http.routers.signaling.entrypoints=websocket"
        - "traefik.http.routers.signaling.service=signaling"
        - "traefik.http.services.signaling.loadbalancer.server.port=8001"
        - "traefik.http.services.signaling.loadbalancer.sticky.cookie=true"
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8001/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging: *default-logging

  # TTS Service - Coqui TTS (1 replica on translation03 for redundancy)
  # Deploy: translation03 (backup replica, lightweight)
  tts_translation03:
    image: jackboun11/jbcalling-tts:redis-cache
    networks:
      - backend
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_TTL=3600
      - TTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
      - TORCH_NUM_THREADS=1
    volumes:
      - models_cache:/root/.cache/TTS
    depends_on:
      - redis
    deploy:
      update_config: *default-update-config
      rollback_config: *default-rollback-config
      restart_policy: *default-restart-policy
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.instance == translation03
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
      labels:
        - "traefik.enable=true"
        - "traefik.http.services.tts.loadbalancer.server.port=8004"
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8004/health\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *default-logging

  # ===========================================================================
  # DEMO SERVICE - REMOVED (Non-production test service)
  # ===========================================================================
  # Reason: TEMPORARY nginx:alpine test page - không dùng trong production
  # Savings: 64MB RAM, 0.1 CPU
  # Domain demo.jbcalling.site sẽ được repurpose cho documentation hoặc guides
  # ===========================================================================

# ==============================================================================
# SUMMARY - RESOURCE ALLOCATION
# ==============================================================================
#
# translation01 (4 cores, 30GB RAM):
#   - Translation: 3.0 CPU, 6GB RAM  (NLLB model)
#   - Traefik:     0.5 CPU, 512MB
#   - Redis:       0.5 CPU, 2GB
#   - Prometheus:  0.5 CPU, 1GB
#   - Grafana:     0.5 CPU, 512MB
#   - Loki:        0.5 CPU, 512MB
#   TOTAL:         5.5 CPU, 10.5GB (có buffer, dùng oversubscription)
#
# translation02 (4 cores, 15GB RAM):
#   - STT:         2.0 CPU, 6GB RAM  (PhoWhisper)
#   - Gateway:     1.5 CPU, 2GB RAM  (MediaSoup)
#   - TTS:         0.5 CPU, 1GB RAM
#   TOTAL:         4.0 CPU, 9GB
#
# translation03 (4 cores, 15GB RAM):
#   - API (x3):    0.75 CPU, 768MB
#   - Frontend(x3):0.3 CPU, 384MB
#   - Signaling(x3):0.75 CPU, 768MB
#   - TTS:         0.5 CPU, 1GB
#   TOTAL:         2.3 CPU, 2.9GB (demo removed, savings: 0.1 CPU, 64MB)
#
# ==============================================================================
